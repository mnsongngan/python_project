{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3610f186",
   "metadata": {},
   "source": [
    "# Data Cleaning in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62a46d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries for ETLs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34d8d735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>UI_version</th>\n",
       "      <th>source</th>\n",
       "      <th>messages</th>\n",
       "      <th>customer_satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50424</td>\n",
       "      <td>11/20/2023 6:04</td>\n",
       "      <td>v1</td>\n",
       "      <td>fb_messenger</td>\n",
       "      <td>{\\n        \"chatbot\": \"Welcome! If you're look...</td>\n",
       "      <td>not sastisfy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50425</td>\n",
       "      <td>11/20/2023 6:11</td>\n",
       "      <td>v1</td>\n",
       "      <td>website</td>\n",
       "      <td>{\\n        \"customer\": \"I thought this razor w...</td>\n",
       "      <td>sastisfy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50426</td>\n",
       "      <td>11/20/2023 6:14</td>\n",
       "      <td>v1</td>\n",
       "      <td>website</td>\n",
       "      <td>{\\n        \"customer\": \"Hey, I need to report ...</td>\n",
       "      <td>sastisfy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50427</td>\n",
       "      <td>11/20/2023 6:26</td>\n",
       "      <td>v1.1.2</td>\n",
       "      <td>website</td>\n",
       "      <td>{\\n        \"customer\": \"Can you point me towar...</td>\n",
       "      <td>sastisfy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50428</td>\n",
       "      <td>11/20/2023 6:26</td>\n",
       "      <td>v2.sp</td>\n",
       "      <td>tiktok</td>\n",
       "      <td>{\\n        \"chatbot\": \"Good day! How can I hel...</td>\n",
       "      <td>sastisfy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID        Timestamp UI_version        source  \\\n",
       "0  50424  11/20/2023 6:04         v1  fb_messenger   \n",
       "1  50425  11/20/2023 6:11         v1       website   \n",
       "2  50426  11/20/2023 6:14         v1       website   \n",
       "3  50427  11/20/2023 6:26     v1.1.2       website   \n",
       "4  50428  11/20/2023 6:26      v2.sp        tiktok   \n",
       "\n",
       "                                            messages customer_satisfaction  \n",
       "0  {\\n        \"chatbot\": \"Welcome! If you're look...          not sastisfy  \n",
       "1  {\\n        \"customer\": \"I thought this razor w...              sastisfy  \n",
       "2  {\\n        \"customer\": \"Hey, I need to report ...              sastisfy  \n",
       "3  {\\n        \"customer\": \"Can you point me towar...              sastisfy  \n",
       "4  {\\n        \"chatbot\": \"Good day! How can I hel...              sastisfy  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_csv('D:\\Lแบบ\\CV\\H22023\\Trusting Social - Data Analytics Test\\data\\Q3_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b9cf9",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87e051bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2016\n"
     ]
    }
   ],
   "source": [
    "# check whether ID column is the primary key (unique customers)\n",
    "print(len(df))\n",
    "print(df['ID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10bc3ac",
   "metadata": {},
   "source": [
    "ID is the primary key &\n",
    "No duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b8cbf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                          0\n",
       "Timestamp                   0\n",
       "UI_version                  0\n",
       "source                      0\n",
       "messages                    0\n",
       "customer_satisfaction    1619\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503e1df",
   "metadata": {},
   "source": [
    "### Deal with missing values: customer_satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d8182f",
   "metadata": {},
   "source": [
    "customer_satisfaction has 1619 null/2016 value.\n",
    "To prevent losing valuable information and reducing the sample size of the dataset, which can affect the validity and generalizability of the analysis, I do not drop the Null value. Instead, as the missing balance is not random, I replace null value with \"no feedback\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff6f600a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['customer_satisfaction'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0828784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                       0\n",
       "Timestamp                0\n",
       "UI_version               0\n",
       "source                   0\n",
       "messages                 0\n",
       "customer_satisfaction    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['customer_satisfaction'] = df['customer_satisfaction'].fillna('no feedback')\n",
    "# check after cleaning\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f45ad9",
   "metadata": {},
   "source": [
    "### Deal with data types (Have not done yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb37d6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                        int64\n",
       "Timestamp                object\n",
       "UI_version               object\n",
       "source                   object\n",
       "messages                 object\n",
       "customer_satisfaction    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ee7a69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m\n\u001b[0;32m     54\u001b[0m     output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m     55\u001b[0m         good_dates[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormattedDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     56\u001b[0m         bad_dates[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormattedDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     57\u001b[0m     ])\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m---> 61\u001b[0m cleaned_df \u001b[38;5;241m=\u001b[39m clean_and_parse_date(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "def clean_and_parse_date(data, correct_date_format):\n",
    "    # Define the possible date formats\n",
    "    date_formats = [\n",
    "        \"%A, %B %d, %Y, %I:%M:%S %p\",  # Example: \"Thursday, November 23, 2023, 3:37:48 PM\"\n",
    "        \"%d/%m/%Y %H:%M\",              # Example: \"23/11/2023 15:37\"\n",
    "        \"%d/%m/%Y %I:%M %p\",           # Example: \"23/11/2023 03:37 PM\"\n",
    "        \"%m/%d/%Y %H:%M:%S\",           # Example: \"11/23/2023 15:37:48\"\n",
    "        \"%m/%d/%Y %I:%M %p\"            # Example: \"11/23/2023 03:37 PM\"\n",
    "    ]\n",
    "    \n",
    "    def parse_date(date_str):\n",
    "        for fmt in date_formats:\n",
    "            try:\n",
    "                return datetime.strptime(date_str, fmt)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return None\n",
    "    \n",
    "    # Apply parsing to the 'Timestamp' column\n",
    "    data['ParsedDate'] = data['Timestamp'].apply(parse_date)\n",
    "    \n",
    "    # Separate into good and bad dates\n",
    "    good_dates = data.dropna(subset=['ParsedDate'])\n",
    "    bad_dates = data[data['ParsedDate'].isna()]\n",
    "    \n",
    "    # Clean bad date entries\n",
    "    def clean_date(date_str):\n",
    "        # Replace common incorrect characters\n",
    "        replacements = ['^', '\\\\', 's', ':', '-']\n",
    "        for ch in replacements:\n",
    "            date_str = date_str.replace(ch, '/')\n",
    "        return date_str\n",
    "    \n",
    "    bad_dates['CleanedTimestamp'] = bad_dates['Timestamp'].apply(clean_date)\n",
    "    bad_dates['ParsedDate'] = bad_dates['CleanedTimestamp'].apply(parse_date)\n",
    "    \n",
    "    # Handle error dates\n",
    "    error_dates = bad_dates[bad_dates['ParsedDate'].isna()]\n",
    "    if not error_dates.empty:\n",
    "        logging.warning(\"All faulty date formatting was not identified. Check output of error_dates.csv for the faulty date formats.\")\n",
    "        error_dates.to_csv('error_dates.csv', index=False)\n",
    "    \n",
    "    # Convert dates to the desired format\n",
    "    if not good_dates.empty:\n",
    "        good_dates['FormattedDate'] = good_dates['ParsedDate'].dt.strftime(correct_date_format)\n",
    "    if not bad_dates.empty:\n",
    "        bad_dates['FormattedDate'] = bad_dates['ParsedDate'].dt.strftime(correct_date_format)\n",
    "    \n",
    "    # Concatenate cleaned data\n",
    "    output = pd.concat([\n",
    "        good_dates[['FormattedDate'] + [col for col in data.columns if col != 'Timestamp']],\n",
    "        bad_dates[['FormattedDate'] + [col for col in data.columns if col != 'Timestamp']]\n",
    "    ])\n",
    "    \n",
    "    return output\n",
    "\n",
    "cleaned_df = clean_and_parse_date(df['Timestamp'], '%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71450f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      NaT\n",
      "1      NaT\n",
      "2      NaT\n",
      "3      NaT\n",
      "4      NaT\n",
      "        ..\n",
      "2011   NaT\n",
      "2012   NaT\n",
      "2013   NaT\n",
      "2014   NaT\n",
      "2015   NaT\n",
      "Name: date_parsed, Length: 2016, dtype: datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                          0\n",
       "Timestamp                   0\n",
       "UI_version                  0\n",
       "source                      0\n",
       "messages                    0\n",
       "customer_satisfaction       0\n",
       "date_parsed              2013\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['date_parsed'])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3544f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae09cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdb958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cd385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
